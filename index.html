<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0" />
    <title>NiiVue</title>
    <link rel="stylesheet" href="./public/niivue.css" />
  </head>
  <body>
    <noscript>
      <strong>niivue requires JavaScript.</strong>
    </noscript>
    <header>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/onnxruntime-web/1.10.0/ort-wasm-threaded.min.js" integrity="sha512-pn8Q0yCw+ZwiqvVoSQxYlC8lvVjFMPGjohVmQgLVqeG2ZUE+/6T6BPvtmqY2tODKg3Mu5M9ROfucTLc+U9J4/Q==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
      <script type="module" src="https://cdn.jsdelivr.net/npm/@niivue/niivue@latest"></script>
      <label for="opacitySlider">Opacity</label>
      <input
        type="range"
        min="0"
        max="255"
        value="128"
        class="slider"
        id="opacitySlider"
      />
      &nbsp;
      <button id="selectAllBtn">Process entire volume</button>
      &nbsp;
      <label for="thicknessDrop">Selection thickness</label>
      <select id="thicknessDrop">
        <option value="0">1</option>
        <option value="2">5</option>
        <option value="4" selected>9</option>
        <option value="5">11</option>
      </select>
      &nbsp;
      <button id="saveBtn">Save Overlay</button>
      &nbsp;
      <label for="dragDrop">Drag mode</label>
      <select id="dragDrop">
        <option>None</option>
        <option>Contrast</option>
        <option>Measurement</option>
        <option>Pan/Zoom</option>
        <option>Slicer3D</option>
        <option selected>Custom Drawing</option>
      </select>
      &nbsp;
      <button id="aboutBtn">About</button>
    </header>
    <main>
      <canvas id="gl1"></canvas>
    </main>
    <footer id="location">&nbsp;</footer>
    <script type="module" async>
      import * as niivue from "./node_modules/@niivue/niivue/dist/index.js";
      import * as ort from "./node_modules/onnxruntime-web/dist/ort.all.mjs";

      function convert_to_png(uint8array, width, height, flip) {
        let offscreen = window.document.createElement('canvas');
        offscreen.width = width;
        offscreen.height = height;
        let offscreen_ctx = offscreen.getContext('2d');
        let imgdata = offscreen_ctx.createImageData(offscreen.width, offscreen.height);
        let pxdata = imgdata.data;

        for (var i = 0; i < pxdata.length; i++) {
          pxdata[i] = uint8array[i];
        }
        offscreen_ctx.putImageData(imgdata, 0, 0);

        if (flip) {
          offscreen_ctx.save();
          offscreen_ctx.scale(1, -1); // Flip vertically
          offscreen_ctx.drawImage(offscreen, 0, -height);
          offscreen_ctx.restore();
        }

        let base64 = offscreen.toDataURL('image/png');
        base64 = base64.replace("data:image/png;base64,", "");

        return Uint8Array.from(atob(base64), (c) => c.charCodeAt(0));
      }

      async function send_http_post(url, data) {
        return new Promise((resolve, reject) => {
          let xhr = new XMLHttpRequest();
          xhr.open("POST", url);
          xhr.onreadystatechange = function () {
            if (xhr.readyState === 4) {
              if (xhr.status === 200) {
                resolve(xhr.response);
              } else {
                reject("Error with request: " + xhr.status);
              }
            }
          };
          xhr.send(data);
        });
      }

      async function ensureOverlayVolumeLoaded() {
        if (nv1.volumes.length !== 1) return;
        let overlayVolume = await nv1.volumes[0].clone();
        overlayVolume.zeroImage();
        nv1.addVolume(overlayVolume);
      }

      async function setup_segment_anything(vox, dims) {
        let url = "https://model-zoo.metademolab.com/predictions/segment_everything_box_model";

        let pixels = vox;
        let width = dims[0];
        let height = dims[2];

        let png_image = convert_to_png(pixels, width, height);

        let result = await send_http_post(url, png_image);
        let embedding = await JSON.parse(result);

        return embedding;
      }

      async function imageProcessing(vox, dims, topleft, bottomright, dir) {
        let embedding = await setup_segment_anything(vox, dims);

        let session = await ort.InferenceSession.create('https://cs666.org/onnx/sam.onnx');

        let input = {};

        let uint8arr = Uint8Array.from(atob(embedding[0]), (c) => c.charCodeAt(0));
        embedding = new ort.Tensor("float32", new Float32Array(uint8arr.buffer), [1, 256, 64, 64]);
        input['low_res_embedding'] = embedding;

        let x1 = topleft[0];
        let y1 = topleft[2];
        let x2 = bottomright[0];
        let y2 = bottomright[2];

        input['point_coords'] = new ort.Tensor("float32", new Float32Array([x1, y1, x2, y2]), [1, 2, 2]);
        input['point_labels'] = new ort.Tensor("float32", new Float32Array([2, 3]), [1, 2]);
        input['image_size'] = new ort.Tensor("float32", new Float32Array([dims[2], dims[0]]));
        input['last_pred_mask'] = new ort.Tensor("float32", new Float32Array(256 * 256), [1, 1, 256, 256]);
        input['has_last_pred'] = new ort.Tensor("float32", new Float32Array([0]));

        return session.run(input).then(result => {
          return result.output.data;
        }).catch(err => {
          console.error(err);
        });
      }

      async function simulate(start, end, axCorSag) {
          console.log("Segmenting")


          await ensureOverlayVolumeLoaded();
          
          let obj = nv1.volumes[0].getVolumeData(start, end);

          let vox = obj[0];
          let dims = obj[1];
          
          let outSliceData = await imageProcessing(vox, dims, start, end, axCorSag);

          nv1.volumes[1].setVolumeData(start, end, outSliceData);
          
          nv1.volumes[1].setColormap('red')
          console.log(nv1.volumes[1])
          nv1.updateGLVolume();

          console.log("Segmented")
        
      }

      var nv1 = new niivue.Niivue();
      nv1.attachTo("gl1");
      nv1.setSliceType(nv1.sliceTypeMultiplanar);
      let simulateVoxStart = [64, 128, 83];
      let simulateVoxEnd = [181, 128, 195];

      let simulateAxCorSag = 1;
      await nv1.loadVolumes([{ url: "./public/stroke.nii.gz" }]);
      await ensureOverlayVolumeLoaded();
      window.nv1 = nv1;

      console.log("Proccessing segmentation")

      await simulate(simulateVoxStart, simulateVoxEnd, simulateAxCorSag);


    </script>
  </body>
</html>
