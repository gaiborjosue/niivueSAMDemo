<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0" />
    <title>NiiVue</title>
    <link rel="stylesheet" href="./public/niivue.css" />
  </head>
  <body>
    <noscript>
      <strong>niivue requires JavaScript.</strong>
    </noscript>
    <header>
      <label for="opacitySlider">Opacity</label>
      <input
        type="range"
        min="0"
        max="255"
        value="128"
        class="slider"
        id="opacitySlider"
      />
      &nbsp;
      <button id="selectAllBtn">Process entire volume</button>
      &nbsp;
      <label for="thicknessDrop">Selection thickness</label>
      <select id="thicknessDrop">
        <option value="0">1</option>
        <option value="2">5</option>
        <option value="4" selected>9</option>
        <option value="5">11</option>
      </select>
      &nbsp;
      <button id="saveBtn">Save Overlay</button>
      &nbsp;
      <label for="dragDrop">Drag mode</label>
      <select id="dragDrop">
        <option>None</option>
        <option>Contrast</option>
        <option>Measurement</option>
        <option>Pan/Zoom</option>
        <option>Slicer3D</option>
        <option selected>Custom Drawing</option>
      </select>
      &nbsp;
      <button id="aboutBtn">About</button>
    </header>
    <main>
      <canvas id="gl1"></canvas>
    </main>
    <footer id="location">&nbsp;</footer>
    <script type="module" async>
      import * as niivue from "./node_modules/@niivue/niivue/dist/index.js";
      import * as ort from "./node_modules/onnxruntime-web/dist/ort.all.mjs";

      opacitySlider.oninput = function () {
        nv1.setOpacity(1, this.value / 255);
      };
      dragDrop.onchange = function () {
        nv1.opts.dragMode = this.selectedIndex;
      };
      function handleLocationChange(data) {
        document.getElementById("location").innerHTML =
          "&nbsp;&nbsp;" + data.string;
      }
      aboutBtn.onclick = function () {
        window.alert(
          "Illustrates reading and writing voxel intensities with getVolumeData and getVolumeData. These functions allow custom image processing."
        );
      };
      saveBtn.onclick = function () {
        nv1.volumes[1].saveToDisk("Custom.nii");
      };

      function convert_to_png(uint8array, width, height, flip) {
        let offscreen = window.document.createElement('canvas');
        offscreen.width = width;
        offscreen.height = height;
        let offscreen_ctx = offscreen.getContext('2d');
        let imgdata = offscreen_ctx.createImageData(offscreen.width, offscreen.height);
        let pxdata = imgdata.data;

        for (var i = 0; i < pxdata.length; i++) {
          pxdata[i] = uint8array[i];
        }
        offscreen_ctx.putImageData(imgdata, 0, 0);

        if (flip) {
          offscreen_ctx.save();
          offscreen_ctx.scale(1, -1); // Flip vertically
          offscreen_ctx.drawImage(offscreen, 0, -height);
          offscreen_ctx.restore();
        }

        let base64 = offscreen.toDataURL('image/png');
        base64 = base64.replace("data:image/png;base64,", "");

        return Uint8Array.from(atob(base64), (c) => c.charCodeAt(0));
      }

      function grayscale_to_rgba(grayscale) {

        const rgba = new Uint8Array(grayscale.length * 4);

        for (let i = 0; i < grayscale.length; i++) {
          const g = grayscale[i];
          const index = i * 4;

          rgba[index] = g;
          rgba[index + 1] = g;
          rgba[index + 2] = g;
          rgba[index + 3] = 255; 
        }

        return rgba;

        }

      function rgba_to_grayscale(rgba) {

        const grayscale = new Uint8Array(rgba.length / 4);

        for (let i = 0; i < rgba.length; i += 4) {

          grayscale[i / 4] = rgba[i];

        }

        return grayscale;

        }

      async function insertImageToCanvas(base64Image) {
        const canvas = document.getElementById('gl1');
        const ctx = canvas.getContext('2d');
        const img = new Image();

        img.onload = function () {
          canvas.width = img.width;
          canvas.height = img.height;
          ctx.drawImage(img, 0, 0);
        };

        img.src = base64Image; // Assign base64 image to the img object
      }

      async function send_http_post(url, data) {
        return new Promise((resolve, reject) => {
          let xhr = new XMLHttpRequest();
          xhr.open("POST", url);
          xhr.onreadystatechange = function () {
            if (xhr.readyState === 4) {
              if (xhr.status === 200) {
                resolve(xhr.response);
              } else {
                reject("Error with request: " + xhr.status);
              }
            }
          };
          xhr.send(data);
        });
      }

      async function ensureOverlayVolumeLoaded() {
        if (nv1.volumes.length !== 1) return;
        let overlayVolume = await nv1.volumes[0].clone();
        overlayVolume.zeroImage();
        overlayVolume.colormap = "actc";
        overlayVolume.opacity = 0.5;
        nv1.addVolume(overlayVolume);
      }

      let normalize = (img) => {
        //  TODO: ONNX not JavaScript https://onnx.ai/onnx/operators/onnx_aionnxml_Normalizer.html
        let mx = img[0]
        let mn = mx
        for (let i = 0; i < img.length; i++) {
          mx = Math.max(mx, img[i])
          mn = Math.min(mn, img[i])
        }
        let scale = 1 / (mx - mn)
        for (let i = 0; i < img.length; i++) {
          img[i] = (img[i] - mn) * scale
        }
      }

      async function setup_segment_anything(vox, dims) {
        console.log("Vox and dims inside SSA");
        console.log(vox, dims);
        let url = "https://model-zoo.metademolab.com/predictions/segment_everything_box_model";

        // let inputSlice32 = new Float32Array(vox)

        /*let pix = rgba_to_grayscale(inputSlice32)

        let newPixelsClamped = new Uint8ClampedArray(pix);
         */

        // normalize(inputSlice32)

        let pixels = vox;
        let width = dims[0];
        let height = dims[2];

        let png_image = convert_to_png(pixels, width, height);

        let result = await send_http_post(url, png_image);
        let embedding = await JSON.parse(result);

        return embedding;
      }



      async function imageProcessing(vox, dims, topleft, bottomright) {
        let embedding = await setup_segment_anything(vox, dims);

        let session = await ort.InferenceSession.create('https://cs666.org/onnx/sam.onnx');

        let input = {};

        console.log(topleft, bottomright);

        let uint8arr = Uint8Array.from(atob(embedding[0]), (c) => c.charCodeAt(0));
        embedding = new ort.Tensor("float32", new Float32Array(uint8arr.buffer), [1, 256, 64, 64]);
        input['low_res_embedding'] = embedding;

        let x1 = topleft[0];
        let y1 = topleft[2];
        let x2 = bottomright[0];
        let y2 = bottomright[2];

        input['point_coords'] = new ort.Tensor("float32", new Float32Array([x1, y1, x2, y2]), [1, 2, 2]);
        input['point_labels'] = new ort.Tensor("float32", new Float32Array([2, 3]), [1, 2]);
        input['image_size'] = new ort.Tensor("float32", new Float32Array([dims[2], dims[0]]));
        input['last_pred_mask'] = new ort.Tensor("float32", new Float32Array(256 * 256), [1, 1, 256, 256]);
        input['has_last_pred'] = new ort.Tensor("float32", new Float32Array([0]));

        return session.run(input).then(result => {
          console.log(result);
          return result.output.data;
        }).catch(err => {
          console.error(err);
        });
      }

      const sigmoid = (x) => {
        return 1 / (1 + Math.exp(-x))
      }

      

      async function doDragRelease(info) {
        if (info.tileIdx >= 0 && info.voxStart[0] >= 0) {
          await ensureOverlayVolumeLoaded();
          let slabPad = parseInt(1);
          let sliceDir = 2;
          if (info.axCorSag === 1) sliceDir = 1;
          if (info.axCorSag === 2) sliceDir = 0;
          info.voxStart[sliceDir] -= slabPad;
          info.voxEnd[sliceDir] += slabPad;
          
          let obj = nv1.volumes[0].getVolumeData(info.voxStart, info.voxEnd, 'float32');
          let vox = obj[0];
          let dims = obj[1];
          
          let outSliceData = await imageProcessing(vox, dims, info.voxStart, info.voxEnd);

          let newPixels = grayscale_to_rgba(outSliceData)

          let pixelsClam = new Uint32Array(newPixels);

            const threshold = 0.55
            // model returns logits, so we need to apply sigmoid.
            for (let i = 0; i < pixelsClam.length; i++) {
              pixelsClam[i] = sigmoid(pixelsClam[i])
              pixelsClam[i] = pixelsClam[i] < threshold ? 0 : 1
            }

          nv1.volumes[1].setVolumeData(info.voxStart, info.voxEnd, newPixels);
          console.log(nv1.volumes[1].cal_min)
          nv1.volumes[1].setColormap('red')
          nv1.updateGLVolume();
        }
      }

      let defaults = {
        onLocationChange: handleLocationChange,
      };
      var nv1 = new niivue.Niivue(defaults);
      nv1.setRadiologicalConvention(false);
      nv1.attachTo("gl1");
      nv1.setSliceType(nv1.sliceTypeMultiplanar);
      nv1.onDragRelease = doDragRelease;
      nv1.opts.dragMode = 5;
      await nv1.loadVolumes([{ url: "./public/stroke.nii.gz" }]);
      await ensureOverlayVolumeLoaded();
    </script>
  </body>
</html>
